{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "univ2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azn28x1d9hIE"
      },
      "source": [
        "# Standard Model ( with oversampling ) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPFBdikx9fQ-"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eLtU8Jf9vha"
      },
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/univ.ai/univ_data/Training Data.csv')\n",
        "#test=pd.read_csv('')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bVBjIce9zao"
      },
      "source": [
        "def preprocessing(df):\n",
        "  df=pd.get_dummies(data=df,columns=[\"house_ownership\",\"married\",\"car_ownership\"],drop_first=True)\n",
        "  df.drop([\"profession\",\"city\",\"state\"],axis=1,inplace=True)\n",
        "  return df"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S8Rxy8e961R",
        "outputId": "ad7dc085-37e3-4866-de10-c5d0b8dba130"
      },
      "source": [
        "train=preprocessing(train)\n",
        "\n",
        "X = train.drop('risk_flag', axis=1)\n",
        "y = train['risk_flag']\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "X_over, y_over = oversample.fit_resample(X,y)\n",
        "X_over=pd.DataFrame(X_over,columns=X.columns)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPt-E1Dw-C_L"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2,shuffle=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTQRgYY_-lMP",
        "outputId": "7e62fe81-49a4-410b-d7f5-62e9047cec52"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(10),\n",
        "    LogisticRegression(),\n",
        "    RandomForestClassifier(),\n",
        "    #GradientBoostingClassifier()\n",
        "    ]\n",
        "for classifier in classifiers:\n",
        "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
        "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3,random_state=1)\n",
        "    scores = cross_val_score(pipe, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "    score = np.mean(scores)\n",
        "    print(classifier)\n",
        "    print('Roc Auc: %.3f' % score)\n",
        "\n",
        "    pipe.fit(X_train,y_train)\n",
        "    y_pred_test=pipe.predict(X_test)\n",
        "    auc_test = roc_auc_score(y_test, y_pred_test)\n",
        "    print('ROC AUC test: %f' % auc_test)\n",
        "    print(\"==========================\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
            "                     weights='uniform')\n",
            "Roc Auc: 0.792\n",
            "ROC AUC test: 0.731935\n",
            "==========================\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Roc Auc: 0.522\n",
            "ROC AUC test: 0.513448\n",
            "==========================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Roc Auc: 0.999\n",
            "ROC AUC test: 0.981064\n",
            "==========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGw4wwUO-_o8",
        "outputId": "102c43ca-5e1b-48cb-e913-bc4038c1e71e"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_params={\n",
        "    'n_neighbors':[3,5,11,15,21],\n",
        "    'weights':['uniform','distance'],\n",
        "    'metric':['euclidean','manhattan']\n",
        "}\n",
        "gs=GridSearchCV(KNeighborsClassifier(),grid_params,verbose=1,cv=3,n_jobs=-1)\n",
        "\n",
        "gs_results=gs.fit(X_over,y_over)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  3.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIkcebxr1rJr"
      },
      "source": [
        "test=pd.read_csv(\"/content/drive/MyDrive/univ.ai/univ_data/Test Data.csv\")\n",
        "ID=test[\"id\"]\n",
        "test=preprocessing(test)\n",
        "predictions=gs_results.predict(test)\n",
        "\n",
        "result=pd.DataFrame()\n",
        "result[\"id\"]=ID\n",
        "result[\"risk_flag\"]=predictions"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8SdLUzt2f9a"
      },
      "source": [
        "result.to_csv(\"predictions2.csv\",index=False)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t5Wm5ni0jzx"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_over,y_over)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDTOBAjztzki"
      },
      "source": [
        "test=preprocessing(test)\n",
        "predictions=knn.predict(test)\n",
        "\n",
        "result=pd.DataFrame()\n",
        "result[\"id\"]=ID\n",
        "result[\"risk_flag\"]=predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bROhUfc_3Fy"
      },
      "source": [
        "# Model with Feature Enginnering "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nvl2XltAA7J"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWrvoD0gAA7K"
      },
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/univ.ai/univ_data/Training Data.csv')\n",
        "#test=pd.read_csv('')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAgR6VECAA7K"
      },
      "source": [
        "def preprocessing(df):\n",
        "  df=pd.get_dummies(data=df,columns=[\"house_ownership\",\"married\",\"car_ownership\"],drop_first=True)\n",
        "  df.drop([\"profession\",\"city\",\"state\"],axis=1,inplace=True)\n",
        "  return df"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz3RJVNmAA7L",
        "outputId": "a63d55e3-3e93-4c5c-d5f5-2c095e85106c"
      },
      "source": [
        "train=preprocessing(train)\n",
        "\n",
        "X = train.drop('risk_flag', axis=1)\n",
        "y = train['risk_flag']\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "X_over, y_over = oversample.fit_resample(X,y)\n",
        "X_over=pd.DataFrame(X_over,columns=X.columns)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdSubflEAA7L"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2,shuffle=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbfYmxiv_81_"
      },
      "source": [
        "transforms = list()\n",
        "transforms.append(('mms', MinMaxScaler()))\n",
        "# transforms.append(('ss', StandardScaler()))\n",
        "# transforms.append(('rs', RobustScaler()))\n",
        "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
        "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
        "transforms.append(('pca', PCA(n_components=7)))\n",
        "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
        "# create the feature union\n",
        "fu = FeatureUnion(transforms)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C57qsRO6AGOm"
      },
      "source": [
        "X_train_new=fu.fit_transform(X_train)\n",
        "X_test_new=fu.transform(X_test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J06R4vY5AP1w",
        "outputId": "14852667-c94a-4b00-e0b5-2f835c7e18f2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "gbc=GradientBoostingClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scores = cross_val_score(gbc, X_train_new, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "print(\"Roc Auc:\",np.mean(scores))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Roc Auc: 0.7346388099008238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVSg905CAYuP"
      },
      "source": [
        "gbc.fit(X_train_new,y_train)\n",
        "y_pred_test=pipe.predict(X_test_new)\n",
        "auc_test = roc_auc_score(y_test, y_pred_test)\n",
        "print('ROC AUC test: %f' % auc_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrkV1r3zZHLE"
      },
      "source": [
        "test=pd.read_csv(\"/content/drive/MyDrive/univ.ai/univ_data/Test Data.csv\")\n",
        "ID=test[\"id\"]\n",
        "\n",
        "test=preprocessing(test)\n",
        "test=fu.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao3EhEnaAzPM"
      },
      "source": [
        "# Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWSbf6_cByGG"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rZiX-bvByGG"
      },
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/univ.ai/univ_data/Training Data.csv')\n",
        "#test=pd.read_csv('')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJoIraifByGH"
      },
      "source": [
        "def preprocessing(df):\n",
        "  df=pd.get_dummies(data=df,columns=[\"house_ownership\",\"married\",\"car_ownership\"],drop_first=True)\n",
        "  df.drop([\"profession\",\"city\",\"state\"],axis=1,inplace=True)\n",
        "  return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-bP0bUbByGH",
        "outputId": "aacdec09-09b2-4da1-eb3e-4e7204bb4816"
      },
      "source": [
        "train=preprocessing(train)\n",
        "\n",
        "X = train.drop('risk_flag', axis=1)\n",
        "y = train['risk_flag']\n",
        "\n",
        "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
        "undersample = NeighbourhoodCleaningRule(n_neighbors=3, threshold_cleaning=0.5)\n",
        "# transform the dataset\n",
        "X_under, y_under = undersample.fit_resample(X, y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkj6jF0oGo_V",
        "outputId": "5ecbab3c-1dc3-443a-d307-c6dd8d9053ae"
      },
      "source": [
        "print(X_under.shape,y_under.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(188433, 10) (188433,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM-bkV9xByGH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.1,shuffle=True)\n",
        "X_train_new=fu.fit_transform(X_under)\n",
        "#X_test_new=fu.transform(X_test)\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler=MinMaxScaler()\n",
        "# X_train=scaler.fit_transform(X_train)\n",
        "# X_test=scaler.transform(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSbxWoCMBuG0",
        "outputId": "dceb2694-69ed-42a3-8b79-3cb17aaeb947"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "gbc=GradientBoostingClassifier()\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "scores = cross_val_score(gbc, X_train_new, y_under, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "print(\"Roc Auc:\",np.mean(scores))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Roc Auc: 0.7700071564572486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhPc4tIwCCm8",
        "outputId": "b9bcb38a-a528-4cb9-ad55-e19462e401e0"
      },
      "source": [
        "gbc.fit(X_train_new,y_under)\n",
        "# y_pred_test=gbc.predict(X_test)\n",
        "# auc_test = roc_auc_score(y_test, y_pred_test)\n",
        "# print('ROC AUC test: %f' % auc_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC test: 0.501935\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}